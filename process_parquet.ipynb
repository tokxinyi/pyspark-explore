{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42377785",
   "metadata": {},
   "source": [
    "# Start a PySpark application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a7d292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/29 06:58:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# edit port number according to what's defined in spark-base.Dockerfile\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"process_parquet\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c101ed0e",
   "metadata": {},
   "source": [
    "# Read the parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a1ae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow = spark.read.parquet(\"./data/raw/yellow_tripdata_2020-01.parquet\")\n",
    "df_green = spark.read.parquet(\"./data/raw/green_tripdata_2020-01.parquet\")\n",
    "df_fhv = spark.read.parquet(\"./data/raw/fhv_tripdata_2020-01.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60600f3b",
   "metadata": {},
   "source": [
    "# Check out the schema of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27f64edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_yellow.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b3e3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: integer (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: double (nullable = true)\n",
      " |-- trip_type: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bcfcf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: double (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhv.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f750ed",
   "metadata": {},
   "source": [
    "# Change the schema of the file\n",
    "Change all columns with LongType to IntegerType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02818f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_yellow = df_yellow\\\n",
    "        .withColumn('VendorID', col('VendorID').cast('integer'))\\\n",
    "        .withColumn('PULocationID', col('PULocationID').cast('integer'))\\\n",
    "        .withColumn('DOLocationID', col('DOLocationID').cast('integer'))\\\n",
    "        .withColumn('payment_type', col('payment_type').cast('integer'))\n",
    "\n",
    "# df_yellow.show()\n",
    "df_yellow.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ebecc",
   "metadata": {},
   "source": [
    "To cast all the columns to the same type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf0b2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       1|          1577838495|           1577838783|              1|            1|         1|              null|         238|         239|           1|          6|    3|      0|         1|           0|                    0|          11|                   2|\n",
      "|       1|          1577838939|           1577839384|              1|            1|         1|              null|         239|         238|           1|          7|    3|      0|         1|           0|                    0|          12|                   2|\n",
      "|       1|          1577839661|           1577840032|              1|            0|         1|              null|         238|         238|           1|          6|    3|      0|         1|           0|                    0|          10|                   2|\n",
      "|       1|          1577840123|           1577840414|              1|            0|         1|              null|         238|         151|           1|          5|    0|      0|         1|           0|                    0|           8|                   0|\n",
      "|       2|          1577836918|           1577837056|              1|            0|         1|              null|         193|         193|           2|          3|    0|      0|         0|           0|                    0|           4|                   0|\n",
      "|       2|          1577837384|           1577837437|              1|            0|         1|              null|           7|         193|           2|          2|    0|      0|         0|           0|                    0|           3|                   0|\n",
      "|       2|          1577839165|           1577839169|              1|            0|         1|              null|         193|         193|           1|          2|    0|      0|         0|           0|                    0|           3|                   0|\n",
      "|       2|          1576682869|           1576682939|              1|            0|         5|              null|         193|         193|           1|          0|    0|      0|         0|           0|                    0|           2|                   2|\n",
      "|       2|          1576683035|           1576683095|              4|            0|         1|              null|         193|         193|           1|          2|    0|      0|         0|           0|                    0|           6|                   2|\n",
      "|       1|          1577838541|           1577839228|              2|            0|         1|              null|         246|          48|           1|          8|    3|      0|         2|           0|                    0|          14|                   2|\n",
      "|       1|          1577840111|           1577841123|              2|            2|         1|              null|         246|          79|           1|         12|    3|      0|         1|           0|                    0|          17|                   2|\n",
      "|       1|          1577839035|           1577839901|              1|            0|         1|              null|         163|         161|           2|          9|    3|      0|         0|           0|                    0|          13|                   2|\n",
      "|       1|          1577840187|           1577841704|              1|            3|         1|              null|         161|         144|           1|         17|    3|      0|         4|           0|                    0|          24|                   2|\n",
      "|       2|          1577838114|           1577838451|              1|            1|         1|              null|          43|         239|           1|          6|    0|      0|         1|           0|                    0|          11|                   2|\n",
      "|       2|          1577839081|           1577841321|              1|            7|         1|              null|         143|          25|           1|         28|    0|      0|         4|           0|                    0|          37|                   2|\n",
      "|       1|          1577837735|           1577838426|              3|            1|         1|              null|         211|         234|           2|          9|    3|      0|         0|           0|                    0|          12|                   2|\n",
      "|       1|          1577839280|           1577839462|              1|            0|         1|              null|         234|          90|           1|          4|    3|      0|         1|           0|                    0|           8|                   2|\n",
      "|       1|          1577840198|           1577841214|              1|            1|         1|              null|         246|         142|           2|         11|    3|      0|         0|           0|                    0|          15|                   2|\n",
      "|       2|          1577837301|           1577838329|              1|            8|         1|              null|         138|         216|           2|         24|    0|      0|         0|           0|                    0|          25|                   0|\n",
      "|       1|          1577838339|           1577838425|              1|            0|         1|              null|         170|         162|           4|          3|    3|      0|         0|           0|                    0|           6|                   2|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_eg = df_yellow.select(*(col(c).cast(\"integer\").alias(c) for c in df_yellow.columns))\n",
    "df_eg.show()\n",
    "# df_eg.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbbfbe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Writing the processed files\n",
    "df_eg.write.parquet('./data/processed/yellow_tripdata_2020-01.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748f470",
   "metadata": {},
   "source": [
    "# Processing all the parquet files we are going to process\n",
    "\n",
    "Converting columns with LongType to Integer Type for the data files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c839f71",
   "metadata": {},
   "source": [
    "## Yellow Taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaed8eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/04\n",
      "processing data for 2020/05\n",
      "processing data for 2020/06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2021/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "year_list = [2020, 2021]\n",
    "for year in year_list:\n",
    "    for month in range(1, 13):\n",
    "        # for month to always have 2 digits\n",
    "        month = str(month).zfill(2)\n",
    "        print(f'processing data for {year}/{month}')\n",
    "        \n",
    "        # read the parquet file\n",
    "        df_yellow = spark.read.parquet(f'./data/raw/yellow_tripdata_{year}-{month}.parquet')\n",
    "        \n",
    "        # convert long to integer type in schema\n",
    "        df_yellow = df_yellow\\\n",
    "        .withColumn('VendorID', col('VendorID').cast('integer'))\\\n",
    "        .withColumn('PULocationID', col('PULocationID').cast('integer'))\\\n",
    "        .withColumn('DOLocationID', col('DOLocationID').cast('integer'))\\\n",
    "        .withColumn('payment_type', col('payment_type').cast('integer'))\n",
    "        \n",
    "        # cast all the data to integer type\n",
    "        df_proc = df_yellow.select(*(col(c).cast(\"integer\").alias(c) for c in df_yellow.columns))\n",
    "        \n",
    "        # write df_proc to a new parquet file\n",
    "        df_proc.write.parquet(f'./data/processed/yellow_tripdata_{year}-{month}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63357a8a",
   "metadata": {},
   "source": [
    "## Green Taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9e5bc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2020/03\n",
      "processing data for 2020/04\n",
      "processing data for 2020/05\n",
      "processing data for 2020/06\n",
      "processing data for 2020/07\n",
      "processing data for 2020/08\n",
      "processing data for 2020/09\n",
      "processing data for 2020/10\n",
      "processing data for 2020/11\n",
      "processing data for 2020/12\n",
      "processing data for 2021/01\n",
      "processing data for 2021/02\n",
      "processing data for 2021/03\n",
      "processing data for 2021/04\n",
      "processing data for 2021/05\n",
      "processing data for 2021/06\n",
      "processing data for 2021/07\n",
      "processing data for 2021/08\n",
      "processing data for 2021/09\n",
      "processing data for 2021/10\n",
      "processing data for 2021/11\n",
      "processing data for 2021/12\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "year_list = [2020, 2021]\n",
    "for year in year_list:\n",
    "    for month in range(1, 13):\n",
    "        # for month to always have 2 digits\n",
    "        month = str(month).zfill(2)\n",
    "        print(f'processing data for {year}/{month}')\n",
    "        \n",
    "        # read the parquet file\n",
    "        df_green = spark.read.parquet(f'./data/raw/green_tripdata_{year}-{month}.parquet')\n",
    "        \n",
    "        # convert long to integer type in schema\n",
    "        df_green = df_green\\\n",
    "        .withColumn('VendorID', col('VendorID').cast('integer'))\\\n",
    "        .withColumn('PULocationID', col('PULocationID').cast('integer'))\\\n",
    "        .withColumn('DOLocationID', col('DOLocationID').cast('integer'))\n",
    "        \n",
    "        # cast all the data to integer type\n",
    "        df_proc = df_green.select(*(col(c).cast(\"integer\").alias(c) for c in df_green.columns))\n",
    "        \n",
    "        # write df_proc to a new parquet file\n",
    "        df_proc.write.parquet(f'./data/processed/green_tripdata_{year}-{month}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb9fa9e",
   "metadata": {},
   "source": [
    "## For-Hire Vehicle\n",
    "\n",
    "There are no columns with LongType, hence no conversion is done for this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38809175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
